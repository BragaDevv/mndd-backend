//openai.ts

import OpenAI from "openai";
import express, { Request, Response } from "express";
import dotenv from "dotenv";

dotenv.config();

const router = express.Router();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Log de inicializa√ß√£o da rota
console.log("‚úÖ Rota /ask da OpenAI configurada.");

router.post("/ask", async (req: Request, res: Response) => {
  const { prompt } = req.body;

  if (!prompt) {
    console.warn("‚ùå Prompt n√£o fornecido.");
    return res.status(400).json({ error: "Prompt n√£o fornecido." });
  }

  console.log(`üì© [OpenAI] Requisi√ß√£o recebida com prompt: ${prompt}`);

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content:
            "Voc√™ √© um assistente b√≠blico crist√£o do Minist√©rio Nascido de Deus (MNDD). " +
            "Responda de forma clara, simples e acolhedora, citando vers√≠culos quando apropriado. " +
            "Mantenha-se estritamente no contexto b√≠blico. " +
            "Se perguntarem sobre cultos ou eventos da igreja, informe que pode verificar os pr√≥ximos eventos. " +
            "Para informa√ß√µes sobre cultos, diga apenas: 'Por favor, pergunte especificamente sobre os cultos para que eu possa verificar.'",
        },
        {
          role: "user",
          content: prompt,
        },
      ],
      temperature: 0.7,
      max_tokens: 500,
    });

    const result = completion.choices[0]?.message?.content;
    console.log("‚úÖ [OpenAI] Resposta gerada:", result);

    return res.status(200).json({ result });
  } catch (error: any) {
    console.error(
      "‚ùå [OpenAI] Erro ao consultar OpenAI:",
      error?.message || error
    );
    return res.status(500).json({ error: "Erro ao consultar OpenAI." });
  }
});

export default router;
